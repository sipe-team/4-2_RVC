잡음, 리버브, 주변 소리, 침 삼키는 소리등 feature를 학습하는데 
즉, 모델은 목소리의 특성보다는 불필요한 소리나 패턴을 학습할 수가 있기에
10분의 깨끗한 녹음이나 1시간의 전화기 품질 녹음이 성능이 현저히 떨어진다고합니다.

잘 정제된 5분짜리 데이터가 1시간짜리 정제되지 않은 데이터보다 낫다는 것입니다.

즉, 톤이나 억양, 감정 등을 잘 담은 고음질 파일을 학습시켜주는 것이 좋은 것 같아요.
그런 의미에서 녹음 이후 어떤 것들을 할 수 있는지 찾아보았습니다.
1. 일단 장비가 어느정도 좋아야합니다. 엄청 비싼 장비까진 아니더라도 집에서 다이나믹 마이크 이상급의 장비로 녹음하는 것이 좋습니다.
2. 정제입니다. 소리가 없는 부분을 자르거나 침소리나 잡음을 제거해주는 것이 좋습니다. 저 같은 경우는 Logic pro라는 daw가 있다보니 해당 daw로 정제해주었습니다.
3. 그래도 최소한의 5분 이상의 데이터는 있어야한다는점. 5분 이상의 질 좋은 데이터가 있으면 무서울 것이 없다. 제일 조심할 건 질 낮은 데이터를 늘려 품질을 악화시키는 것을 조심하자.

그럼 내부 관점에서 봐보겠습니다.
RVC는 크게 다음 방식으로 작동합니다.
1. 음성 입력 받기 
2. Hubert 모델로 음성의 내용과 발화 특성을 추출하고  f0 (피치)를 추출한다.
3. Generator와 Content Encoder를 통한 음성 변환 모델 학습
4. 음성 합성

여기서 2번과 3번이 데이터 질에 직접적으로 영향을 주는데요.
Huber모델은 음성의 내용과 발화 특성을 추출하는데 Hubert는 잡음이나 리버브에 매우 민감하다고 합니다.
그렇기에 데이터의 무의미한 음향 정보가 들어가면 이게 말의 내용인지, 잡음인지 혼동한다고 해요. 그래서 만약 잡음이 많으면 목소리가 아닌 녹음 당시 환경에 대한 학습을 진행하게되어 퀄리티가 떨어질 수 있습니다.

즉 Hubert가 제대로 추출을 못하는거죠.
그리고 f0, 피치 추출도 문제입니다. RVC는 F0이라는 음높이, 즉 피치를 추출해서 모델의 conditioning으로 넣는다고 합니다. 
그러니 잡음이 섞이는 경우 f0이 튈 수가 있습니다.
f0이 튄다는거는 “저는 이용진입니다” 이라는 말이 있으면 말의 피치가 음절이나 단어, 글자마다 존재하는데 이게 정상적인 피치 움직임에서 벗어난다는 것입니다.
```
ex )  “저는 이용진입니다” → [F0: 180Hz → 20Hz → 피치가 튀어서 말이 끊김 → 0Hz → 다시 200Hz]
```
* 여기서 conditioning이란 모델이 어떤 '추가 정보'를 참고해서 출력을 바꾸게 만드는 것


이게 2번 과정에서 데이터 질이 잘못되면 발생할 수 있는 문제였고요.
3번 과정에서도 문제가 발생할 수 있습니다.

이 과정에서 학습을 거치게 되는 것인데요. 2번에서 추출한 Content, F0, wav데이터를 기반으로 목소리를 특정 타겟이 되는 화자의 음색으로 변환하는 모델 학습을 진행합니다.

이 3번 과정의 학습 과정이 참 재미있는데요. 
Content, f0으로 Generator를 통해 음성 생성하는 변환 함수를 만들고 
Generator가 만든 음성과 진짜 우리가 녹음했던 원본 음성과 비교해서 둘의 차이를 줄이도록 가중치를 업데이트하여 학습합니다.

즉 요약하면 
1. 입력: Content, f0을 입력 받고
2. 이걸 목소리로 말한 것처럼 음성을 생성하고 
3. 이 생성된 예측 음성과 원본 wav를 비교해서 이 둘의 Loss값를 계산하고 Loss값를 바탕으로 둘의 차이를 줄이는 가중치(weight)를 업데이트한다.

이 과정을 계속 반복하면 점점 모델이 목소리 스타일을 익히게 되는 것입니다.

* Loss는 "예측 결과"와 "정답"의 차이를 숫자로 표현한 값입니다.

  

그리고 여기서 또 알아버린 점은 결국 `.pth` 모델은 “이 사람이 이렇게 말하면, 목소리를 따라 하고 싶은 사람은 이렇게 말하겠지” 를 담은 **목소리 변환 매핑 함수라는 것입니다..!**

그래서 아까 하던 말을 이어서 하자면 이 Generator는 또 Content Encoder와 Speaker Embedding과 Pitch Encoding이라는 걸로 구성되어있는데, Content Encoder는 입력 음성에서 내용 정보를 추출하고 Speak Embedding은 목소리의 특징을 추출한다고 합니다.
하지만 음성에 잡음이나 리버브가 포함되어 있으면 Content Encoder는 이것조차 내용으로 학습을 해버리는 것이죠. 그래서 말투나 억양이 아닌 잡음을 재현하게 될 수 있어서 또 이 과정에서 결과가 안 좋게 되버릴 수 있다는 것입니다.

그래서 결론은 음성 파일의 질이 안 좋으면
1. Hubert 모델은 말의 내용과 발화의 특성을 추출하는데 말의 내용이 아닌 잡음을 학습하게 될 수 있음.
2. F0 추출시 잡음이 섞이면 엉뚱한 피치의 패턴을 학습하게 될 수 있음.
3. Generator의 Content encoder가 음성의 잡음이나 리버브를 학습해서 말투나 억양이 아닌 잡음을 재현하게 될 수 있기에 결과가 안 좋게 나올 수 있다. 
입니다.

결론 음성의 질을 좋게 하자.
